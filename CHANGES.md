# Thay Ä‘á»•i: Chuyá»ƒn tá»« crawl4ai sang requests

## TÃ³m táº¯t
ÄÃ£ chuyá»ƒn tá»« sá»­ dá»¥ng `crawl4ai` (vá»›i Playwright/Chromium) sang sá»­ dá»¥ng `requests` Ä‘á»ƒ crawl dá»¯ liá»‡u. Äiá»u nÃ y lÃ m cho:
- âœ… Khá»Ÿi Ä‘á»™ng nhanh hÆ¡n (khÃ´ng cáº§n cÃ i Playwright browsers)
- âœ… Image Docker nhá» hÆ¡n nhiá»u (~200MB thay vÃ¬ ~2GB)
- âœ… Sá»­ dá»¥ng Ã­t tÃ i nguyÃªn hÆ¡n (RAM, CPU)
- âœ… Code Ä‘Æ¡n giáº£n hÆ¡n, dá»… maintain

## Files Ä‘Ã£ thay Ä‘á»•i

### 1. `crawler.py`
- âŒ XÃ³a: `from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, BrowserConfig`
- âŒ XÃ³a: `import asyncio`
- âœ… ThÃªm: `import requests`
- âœ… ThÃªm: `import time`
- ğŸ”„ Chuyá»ƒn cÃ¡c hÃ m tá»« `async def` sang `def` (synchronous)
- âœ… ThÃªm hÃ m `fetch_tax_info()` - crawl Ä‘Æ¡n giáº£n báº±ng requests
- ğŸ”„ Cáº­p nháº­t `crawl_multiple_tax_codes()` vÃ  `crawl_multiple_tax_codes_with_progress()`

### 2. `app.py`
- ğŸ”„ XÃ³a `await` khi gá»i `crawl_tax_code()`
- ğŸ”„ XÃ³a `await` khi gá»i `crawl_multiple_tax_codes_with_progress()`
- ğŸ”„ Chuyá»ƒn background task tá»« `asyncio.create_task()` sang `threading.Thread()`
- âœ… Giá»¯ `asyncio` cho SSE streaming (váº«n cáº§n thiáº¿t)

### 3. `main.py`
- âŒ XÃ³a: `import asyncio`
- ğŸ”„ Chuyá»ƒn `cli_example()` tá»« `async def` sang `def`
- ğŸ”„ XÃ³a `await` khi gá»i `crawl_tax_code()`
- ğŸ”„ Thay `asyncio.run(cli_example())` báº±ng `cli_example()`

### 4. `pyproject.toml`
- âŒ XÃ³a: `"crawl4ai>=0.3.0"`
- âœ… ThÃªm: `"requests>=2.31.0"`

### 5. `Dockerfile`
- âŒ XÃ³a: Táº¥t cáº£ dependencies cá»§a Playwright/Chromium (libnss3, libnspr4, etc.)
- âŒ XÃ³a: `playwright install chromium --with-deps`
- âŒ XÃ³a: `ENV PLAYWRIGHT_BROWSERS_PATH=/app/browsers`
- ğŸ”„ Giáº£m `start_period` trong healthcheck tá»« 40s xuá»‘ng 5s

### 6. `docker-compose.yml`
- ğŸ”„ Giáº£m `start_period` trong healthcheck tá»« 40s xuá»‘ng 10s

## CÃ¡ch sá»­ dá»¥ng

### Test local
```bash
# Sync dependencies
uv sync

# Test single tax code
uv run python test_crawler.py

# Test CLI
uv run python main.py

# Start web server
uv run python main.py web
```

### Deploy vá»›i Docker
```bash
# Build image (nhanh hÆ¡n vÃ  nháº¹ hÆ¡n)
docker build -t tax-crawler:latest .

# Run vá»›i docker-compose
docker-compose up -d

# Hoáº·c run trá»±c tiáº¿p
docker run -d -p 8102:8102 --name tax-crawler tax-crawler:latest
```

## API khÃ´ng thay Ä‘á»•i
Táº¥t cáº£ endpoints vÃ  responses váº«n giá»¯ nguyÃªn:
- `POST /crawl` - Crawl single tax code
- `POST /crawl_csv` - Upload CSV vÃ  crawl nhiá»u tax codes
- `GET /progress/{session_id}` - SSE progress stream
- `GET /results/{session_id}` - Láº¥y káº¿t quáº£ sau khi crawl xong
- `POST /download_excel` - Download Excel

## Performance
- Khá»Ÿi Ä‘á»™ng: ~2-3 giÃ¢y (trÆ°á»›c: ~30-40 giÃ¢y)
- Docker image: ~200MB (trÆ°á»›c: ~2GB)
- RAM usage: ~100-200MB (trÆ°á»›c: ~500MB-1GB)
- Crawl speed: TÆ°Æ¡ng tá»± (váº«n cÃ³ delay giá»¯a cÃ¡c request Ä‘á»ƒ trÃ¡nh spam)

## Notes
- Váº«n sá»­ dá»¥ng BeautifulSoup Ä‘á»ƒ parse HTML
- Váº«n cÃ³ random delay giá»¯a cÃ¡c requests
- Váº«n há»— trá»£ progress tracking qua SSE
- Code Ä‘Æ¡n giáº£n hÆ¡n, dá»… debug hÆ¡n

